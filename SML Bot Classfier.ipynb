{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datahandling\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import \n",
    "data = pd.read_csv('detection_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   User ID        Username                                              Tweet  \\\n",
      "0   132131           flong  Station activity person against natural majori...   \n",
      "1   289683  hinesstephanie  Authority research natural life material staff...   \n",
      "2   779715      roberttran  Manage whose quickly especially foot none to g...   \n",
      "3   696168          pmason  Just cover eight opportunity strong policy which.   \n",
      "4   704441          noah87                      Animal sign six data good or.   \n",
      "\n",
      "   Retweet Count  Mention Count  Follower Count  Verified  Bot Label  \\\n",
      "0             85              1            2353     False          1   \n",
      "1             55              5            9617      True          0   \n",
      "2              6              2            4363      True          0   \n",
      "3             54              5            2242      True          1   \n",
      "4             26              3            8438     False          1   \n",
      "\n",
      "       Location           Created At            Hashtags  \n",
      "0     Adkinston  2020-05-11 15:29:50                 NaN  \n",
      "1    Sanderston  2022-11-26 05:18:10           both live  \n",
      "2  Harrisonfurt  2022-08-08 03:16:54         phone ahead  \n",
      "3  Martinezberg  2021-08-14 22:27:05  ever quickly new I  \n",
      "4  Camachoville  2020-04-13 21:24:21     foreign mention  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   User ID         50000 non-null  int64 \n",
      " 1   Username        50000 non-null  object\n",
      " 2   Tweet           50000 non-null  object\n",
      " 3   Retweet Count   50000 non-null  int64 \n",
      " 4   Mention Count   50000 non-null  int64 \n",
      " 5   Follower Count  50000 non-null  int64 \n",
      " 6   Verified        50000 non-null  bool  \n",
      " 7   Bot Label       50000 non-null  int64 \n",
      " 8   Location        50000 non-null  object\n",
      " 9   Created At      50000 non-null  object\n",
      " 10  Hashtags        41659 non-null  object\n",
      "dtypes: bool(1), int64(5), object(5)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"\\nBasic information about the dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (792158155.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    X = data.drop(columns=Bot Label'el'])  # Features\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "# Assuming \"label\" column contains 0 (human) or 1 (bot) labels\n",
    "X = data.drop(column['s=Bot Lalbel'el'])  # Features\n",
    "y = daBot Labelabel']  # Target\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Model Selection: Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Feature Selection: Experimenting with K best features\n",
    "def select_features(X_train, y_train, X_val, k=10):\n",
    "    selector = SelectKBest(score_func=chi2, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_val_selected = selector.transform(X_val)\n",
    "    return X_train_selected, X_val_selected, selector\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Model Training and Hyperparameter Tuning\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    # Try feature selection\n",
    "    X_train_selected, X_val_selected, selector = select_features(X_train, y_train, X_val, k=10)\n",
    "\n",
    "    # Hyperparameter tuning (simple example using grid search for RandomForest)\n",
    "    if name == \"Random Forest\":\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [None, 10, 20]\n",
    "        }\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train_selected, y_train)\n",
    "        model = grid_search.best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Validation\n",
    "    y_val_pred = model.predict(X_val_selected)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "    # Save results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel Evaluation Results on Validation Set:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    for metric, score in metrics.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "\n",
    "# Model Evaluation on Test Set with the Best Model\n",
    "best_model_name = max(results, key=lambda k: results[k]['Accuracy'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Transform test set using the selected features\n",
    "X_test_selected = selector.transform(X_test)\n",
    "y_test_pred = best_model.predict(X_test_selected)\n",
    "\n",
    "# Final Evaluation Metrics\n",
    "print(\"\\nFinal Evaluation on Test Set with Best Model:\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"Test Set ROC AUC: {roc_auc_score(y_test, y_test_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
